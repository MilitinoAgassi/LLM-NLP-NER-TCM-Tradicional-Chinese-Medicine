{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Pyp8XIoseI9J",
        "xPbUicMZhjex",
        "SLCkMZd7oxek",
        "aJqoTlC7-zBT",
        "7SZS_pVq_TsJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Link Dataset Compartilhado\n",
        "\n",
        "https://drive.google.com/file/d/1G-pr-ltNCUq_WYMrgWRZIcdlRANJndy0/view?usp=drive_link\n",
        "\n",
        "https://drive.google.com/file/d/1G-pr-ltNCUq_WYMrgWRZIcdlRANJndy0/view?usp=sharing"
      ],
      "metadata": {
        "id": "t2iSrXFud8v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação de Bibliotecas\n"
      ],
      "metadata": {
        "id": "Pyp8XIoseI9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1T0xmUFdivU"
      },
      "outputs": [],
      "source": [
        "# Instalação de Biblioteca\n",
        "\n",
        "!pip install torch transformers seqeval pytorch-crf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação de Biblioteca para Alibaba QWEN3 modelo arquitetura LLM\n",
        "\n",
        "!pip install transformers torch seqeval torchcrf accelerate\n"
      ],
      "metadata": {
        "id": "URDxZEzBfh6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redução do estouro de memória durante no treinamento, evitando OOM\n",
        "\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
      ],
      "metadata": {
        "id": "YGZpNP5lf8nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar Bibliotecas para Leitura do JSON\n",
        "\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast"
      ],
      "metadata": {
        "id": "08bpI3R0h1s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar GitHub LFS\n",
        "\n",
        "!git lfs install"
      ],
      "metadata": {
        "id": "rCw28kvBgG58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar arquivo compactado clone modelo treinado do repositório GitHub\n",
        "\n",
        "!git clone https://github.com/MilitinoAgassi/LLM-NLP-NER-TCM-Tradicional-Chinese-Medicine.git"
      ],
      "metadata": {
        "id": "qERX9w1Dgnqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descompactar arquivo zip\n",
        "\n",
        "# Criar diretório do destino\n",
        "!mkdir -p /content/outputs_qwen_ner\n",
        "\n",
        "# Descompactar arquivos para pasta do destino\n",
        "\n",
        "!unzip LLM-NLP-NER-TCM-Tradicional-Chinese-Medicine/outputs_qwen_ner.zip -d /content/outputs_qwen_ner"
      ],
      "metadata": {
        "id": "0xxfvDVYg6J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar os arquivos descompactados\n",
        "\n",
        "!ls -lh outputs_qwen_ner"
      ],
      "metadata": {
        "id": "52SDTdG_hQ_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leitura do Dataset"
      ],
      "metadata": {
        "id": "xPbUicMZhjex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura Database Train (Treino)"
      ],
      "metadata": {
        "id": "PAA8AKdsh_Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura Database Train.json\n",
        "\n",
        "with open (\"train.json\" , \"r\" , encoding=\"utf-8\") as File:\n",
        "  Train_data = json.load(File)\n",
        "\n",
        "print(Train_data)"
      ],
      "metadata": {
        "id": "Km-ty05giCwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar Database Train\n",
        "\n",
        "for item in Train_data:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "-2_wOFLEiFBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime as chaves do primeiro elemento Train_data\n",
        "\n",
        "print(Train_data[0].keys())"
      ],
      "metadata": {
        "id": "nihblCediKJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime a chave labels do Train_data\n",
        "\n",
        "for item in Train_data:\n",
        "  Labels_Train_data = item[\"labels\"]\n",
        "  print(Labels_Train_data)"
      ],
      "metadata": {
        "id": "t-ph0EZEjCMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho Quantidade no Train_data\n",
        "\n",
        "print(len(Train_data))"
      ],
      "metadata": {
        "id": "trVe05EnjGng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho Quantidade Número de Keys no Train_data\n",
        "\n",
        "print(len(Train_data[0]))"
      ],
      "metadata": {
        "id": "WxRq4Nn2jIwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura Database Dev (Validação)"
      ],
      "metadata": {
        "id": "tCKlECE7jQ1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura Database Dev.json\n",
        "\n",
        "with open (\"dev.json\" , \"r\" , encoding=\"utf-8\") as File:\n",
        "  Dev_data = json.load(File)\n",
        "\n",
        "print(Dev_data)"
      ],
      "metadata": {
        "id": "e4X1wUavjUgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar Database Dev\n",
        "\n",
        "for item in Dev_data:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "xGAPkFEMjdLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime as chaves do primeiro elemento Dev_data\n",
        "\n",
        "print(Dev_data[0].keys())"
      ],
      "metadata": {
        "id": "rxagjhOhjgOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime a chave labels do Dev_data\n",
        "\n",
        "for item in Dev_data:\n",
        "  Labels_Dev_data = item[\"labels\"]\n",
        "  print(Labels_Dev_data)"
      ],
      "metadata": {
        "id": "yxfzXJDsjjEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho Quantidade no Dev_data\n",
        "\n",
        "print(len(Dev_data))"
      ],
      "metadata": {
        "id": "QklcxMGHjlxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho Quantidade Número de Keys no Dev_data\n",
        "\n",
        "print(len(Dev_data[0]))\n"
      ],
      "metadata": {
        "id": "0SF9vYKGjn3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura Database Test (Teste)"
      ],
      "metadata": {
        "id": "P7br28wSjs72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura Database Test.json\n",
        "\n",
        "with open (\"test.json\" , \"r\" , encoding=\"utf-8\") as File:\n",
        "  Test_data = json.load(File)\n",
        "\n",
        "print(Test_data)"
      ],
      "metadata": {
        "id": "98GwhN2ajwrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in Test_data:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "0HyjoyrEjzPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime as chaves do primeiro elemento Test_data\n",
        "\n",
        "print(Test_data[0].keys())"
      ],
      "metadata": {
        "id": "awcluHyxj2yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho Quantidade no Test_data\n",
        "\n",
        "print(len(Test_data))"
      ],
      "metadata": {
        "id": "RQW68ZDBkWgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho Quantidade Número de Keys no Test_data\n",
        "\n",
        "print(len(Test_data[0]))"
      ],
      "metadata": {
        "id": "sHcxUIC6kYMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura Database CRF_ent2id (Entidades Principais)"
      ],
      "metadata": {
        "id": "fkePkhuKlMmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura Database CRF_ent2id.json\n",
        "\n",
        "with open (\"crf_ent2id.json\" , \"r\" , encoding=\"utf-8\") as File:\n",
        "  CRF_ent2id_data = json.load(File)\n",
        "\n",
        "print(CRF_ent2id_data)"
      ],
      "metadata": {
        "id": "qscmBpStlUgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização das Entidades\n",
        "\n",
        "for item in CRF_ent2id_data:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "kR3PiUQxlWWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho Quantidade no CRF_ent2id_data\n",
        "\n",
        "print(len(CRF_ent2id_data))"
      ],
      "metadata": {
        "id": "MoXwJUfTlc9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação Dados Duplicados em Train/Dev/Test"
      ],
      "metadata": {
        "id": "IcrdR93-l7v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Versão Avançada\n",
        "\n",
        "import json\n",
        "\n",
        "def load_ids(path):\n",
        "    \"\"\"Leitura JSON Retornar Todas Amostras id \"\"\"\n",
        "    data = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
        "    return set([d[\"id\"] for d in data])\n",
        "\n",
        "def check_splits(train_path, dev_path, test_path):\n",
        "    train_ids = load_ids(train_path)\n",
        "    dev_ids = load_ids(dev_path)\n",
        "    test_ids = load_ids(test_path)\n",
        "\n",
        "    print(\"=== Tamanho Database ===\")\n",
        "    print(f\"Train: {len(train_ids)} Dados\")\n",
        "    print(f\"Dev:   {len(dev_ids)} Dados\")\n",
        "    print(f\"Test:  {len(test_ids)} Dados\\n\")\n",
        "\n",
        "    # Verificação Cruzada\n",
        "    inter_train_dev = train_ids & dev_ids\n",
        "    inter_train_test = train_ids & test_ids\n",
        "    inter_dev_test = dev_ids & test_ids\n",
        "\n",
        "    print(\"=== Verificação Cruzada ===\")\n",
        "    print(\"Train ∩ Dev:\", inter_train_dev)\n",
        "    print(\"Train ∩ Test:\", inter_train_test)\n",
        "    print(\"Dev ∩ Test:\", inter_dev_test)\n",
        "\n",
        "    # Alerta\n",
        "    if inter_train_dev or inter_train_test or inter_dev_test:\n",
        "        print(\"\\n⚠️ Alerta：Amostras Duplicadas！\")\n",
        "        if inter_train_dev:\n",
        "            print(f\"  - Train e Dev Duplicadas {len(inter_train_dev)} Dados\")\n",
        "        if inter_train_test:\n",
        "            print(f\"  - Train e Test Duplicadas {len(inter_train_test)} Dados\")\n",
        "        if inter_dev_test:\n",
        "            print(f\"  - Dev e Test Duplicadas {len(inter_dev_test)} Dados\")\n",
        "    else:\n",
        "        print(\"\\n✅ Parabéns！Train / Dev / Test Três Databese Independente，Não há Duplicidade。\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # check_splits(\"Train_data.json\", \"Dev_data.json\", \"Test_data.json\")\n",
        "    check_splits(\"train.json\", \"dev.json\", \"test.json\")"
      ],
      "metadata": {
        "id": "obq-2QvjmFr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformação Limpeza dos Dados / Geração de Embeddings / SPAN BIOS"
      ],
      "metadata": {
        "id": "SLCkMZd7oxek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correção Estrutura Formato Label Entidade do CRF2ID\n",
        "\n",
        "import json\n",
        "\n",
        "# Load the current data from crf_ent2id.json\n",
        "with open(\"crf_ent2id.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    crf_data = json.load(f)\n",
        "\n",
        "# Extract only the label names (the keys of the dictionary)\n",
        "label_names = list(crf_data.keys())\n",
        "\n",
        "# Define the corrected filename\n",
        "corrected_label_file = \"crf_ent2id_corrected.txt\"\n",
        "\n",
        "# Write the corrected label names to a new file, one per line\n",
        "with open(corrected_label_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for label in label_names:\n",
        "        f.write(label + \"\\n\")\n",
        "\n",
        "print(f\"Corrected label file saved as: {corrected_label_file}\")\n",
        "\n",
        "# You can now use 'crf_ent2id_corrected.txt' in your conversion script\n",
        "# For example, you can modify the convert_split function calls to use this new file:\n",
        "# convert_split(..., label_file=corrected_label_file, ...)"
      ],
      "metadata": {
        "id": "FhHQCie1rlgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar Label ID CRF2ID Corrigida\n",
        "\n",
        "import json\n",
        "\n",
        "def load_label_set(label_file: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
        "    labels = []\n",
        "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            t = line.strip()\n",
        "            if t:\n",
        "                labels.append(t)\n",
        "    if \"O\" not in labels:\n",
        "        labels = [\"O\"] + labels\n",
        "    label2id = {l: i for i, l in enumerate(labels)}\n",
        "    id2label = {i: l for l, i in label2id.items()}\n",
        "    return label2id, id2label\n",
        "\n",
        "label2id, id2label = load_label_set(\"crf_ent2id_corrected.txt\")\n",
        "\n",
        "print(\"Label ID to Name Mapping (using crf_ent2id_corrected.txt):\")\n",
        "for id, name in id2label.items():\n",
        "    print(f\"{id}: {name}\")"
      ],
      "metadata": {
        "id": "Y2ewI1Zv02ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação Conversão Alinhamento Normalização Database com SPAN BIOS\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "convert_bioes_final.py\n",
        " span (start, end, type) alignment BERT tokens，output BIOES Label Sequence。\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Tuple\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# ========== LIMPEZA ==========\n",
        "def clean_text(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = text.replace(\"<br/>\", \"\").replace(\"<br>\", \"\")\n",
        "    text = text.replace(\"\\u3000\", \"\")\n",
        "    text = re.sub(r\"[\\u200b\\u200c\\u200d\\u2060]\", \"\", text)\n",
        "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "# ========== LABEL ==========\n",
        "def load_label_set(label_file: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
        "    labels = []\n",
        "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            t = line.strip()\n",
        "            if t:\n",
        "                labels.append(t)\n",
        "    if \"O\" not in labels:\n",
        "        labels = [\"O\"] + labels\n",
        "    label2id = {l: i for i, l in enumerate(labels)}\n",
        "    id2label = {i: l for l, i in label2id.items()}\n",
        "    return label2id, id2label\n",
        "\n",
        "# ========== LEIRUTA ==========\n",
        "def load_json(path: str) -> List[Dict]:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read().strip()\n",
        "    if not content:\n",
        "        return []\n",
        "    if content.startswith(\"[\"):\n",
        "        return json.loads(content)\n",
        "    return [json.loads(line) for line in content.splitlines() if line.strip()]\n",
        "\n",
        "# ========== NOMALIZAÇÃO SPAN ==========\n",
        "def normalize_spans(label_items: List[List], end_inclusive: bool) -> List[Tuple[int, int, str]]:\n",
        "    spans = []\n",
        "    for it in label_items or []:\n",
        "        if len(it) >= 4:\n",
        "            typ = str(it[1])\n",
        "            start = int(it[2])\n",
        "            end = int(it[3])\n",
        "            if end_inclusive:\n",
        "                end = end + 1\n",
        "            spans.append((start, end, typ))\n",
        "    return spans\n",
        "\n",
        "# ========== span → BIOES ==========\n",
        "def spans_to_bioes_for_offsets(text: str, spans: List[Tuple[int, int, str]],\n",
        "                               offset_mapping: List[Tuple[int, int]],\n",
        "                               label2id: Dict[str, int]) -> List[int]:\n",
        "    labels_ids = [label2id[\"O\"]] * len(offset_mapping)\n",
        "\n",
        "    def token_indices_for_span(start: int, end: int) -> List[int]:\n",
        "        idxs = []\n",
        "        for ti, (s, e) in enumerate(offset_mapping):\n",
        "            if s == e:\n",
        "                continue\n",
        "            if max(0, min(e, end) - max(s, start)) > 0:\n",
        "                idxs.append(ti)\n",
        "        return idxs\n",
        "\n",
        "    for (start_char, end_char, etype) in spans:\n",
        "        idxs = token_indices_for_span(start_char, end_char)\n",
        "        if not idxs:\n",
        "            continue\n",
        "        if len(idxs) == 1:\n",
        "            labels_ids[idxs[0]] = label2id.get(f\"S-{etype}\", label2id[\"O\"])\n",
        "        else:\n",
        "            labels_ids[idxs[0]] = label2id.get(f\"B-{etype}\", label2id[\"O\"])\n",
        "            for k in idxs[1:-1]:\n",
        "                labels_ids[k] = label2id.get(f\"I-{etype}\", label2id[\"O\"])\n",
        "            labels_ids[idxs[-1]] = label2id.get(f\"E-{etype}\", label2id[\"O\"])\n",
        "    return labels_ids\n",
        "\n",
        "# ========== CONVERSÃO ==========\n",
        "def convert_split(input_json: str, label_file: str, model_name: str,\n",
        "                  output_path: str, max_len: int = 512,\n",
        "                  end_inclusive: bool = False, apply_cleaning: bool = True,\n",
        "                  split_by_char: bool = True):\n",
        "    label2id, _ = load_label_set(label_file)\n",
        "    tok = BertTokenizerFast.from_pretrained(model_name)\n",
        "    data = load_json(input_json)\n",
        "\n",
        "    out_samples = []\n",
        "    for ex in data:\n",
        "        raw_text = ex.get(\"text\", \"\")\n",
        "        text = clean_text(raw_text) if apply_cleaning else raw_text\n",
        "\n",
        "        if split_by_char:\n",
        "            enc = tok(list(text), is_split_into_words=True,\n",
        "                      truncation=True, max_length=max_len,\n",
        "                      return_offsets_mapping=True)\n",
        "        else:\n",
        "            enc = tok(text, truncation=True, max_length=max_len,\n",
        "                      return_offsets_mapping=True)\n",
        "\n",
        "        spans = normalize_spans(ex.get(\"labels\", []), end_inclusive=end_inclusive)\n",
        "        labels_ids = spans_to_bioes_for_offsets(text, spans, enc[\"offset_mapping\"], label2id)\n",
        "\n",
        "        out_samples.append({\n",
        "            \"id\": ex.get(\"id\"),\n",
        "            \"input_ids\": enc[\"input_ids\"],\n",
        "            \"attention_mask\": enc[\"attention_mask\"],\n",
        "            \"labels\": labels_ids\n",
        "        })\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(out_samples, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"[OK] Converted {len(out_samples)} samples → {output_path}\")\n",
        "\n",
        "# Call the conversion functions directly\n",
        "convert_split(\n",
        "    input_json=\"train.json\",\n",
        "    label_file=\"crf_ent2id_corrected.txt\",\n",
        "    model_name=\"hfl/chinese-bert-wwm-ext\",\n",
        "    output_path=\"converted_train.json\",\n",
        "    max_len=512,\n",
        "    end_inclusive=False,\n",
        "    apply_cleaning=True,\n",
        "    split_by_char=False,\n",
        ")\n",
        "\n",
        "convert_split(\n",
        "    input_json=\"dev.json\",\n",
        "    label_file=\"crf_ent2id_corrected.txt\",\n",
        "    model_name=\"hfl/chinese-bert-wwm-ext\",\n",
        "    output_path=\"converted_dev.json\",\n",
        "    max_len=512,\n",
        "    end_inclusive=False,\n",
        "    apply_cleaning=True,\n",
        "    split_by_char=False,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "8uBFAvbDsk5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribuição do Label Type\n",
        "\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "# Load the converted training data\n",
        "with open(\"converted_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    converted_train_data = json.load(f)\n",
        "\n",
        "# Load id2label mapping from the corrected file\n",
        "def load_label_set(label_file: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
        "    labels = []\n",
        "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            t = line.strip()\n",
        "            if t:\n",
        "                labels.append(t)\n",
        "    if \"O\" not in labels:\n",
        "        labels = [\"O\"] + labels\n",
        "    label2id = {l: i for i, l in enumerate(labels)}\n",
        "    id2label = {i: l for l, i in label2id.items()}\n",
        "    return label2id, id2label\n",
        "\n",
        "label2id, id2label = load_label_set(\"crf_ent2id_corrected.txt\")\n",
        "\n",
        "# Extract all label IDs from the training data\n",
        "all_train_labels = []\n",
        "for entry in converted_train_data:\n",
        "    all_train_labels.extend(entry[\"labels\"])\n",
        "\n",
        "# Count the occurrences of each label ID\n",
        "label_id_counts = Counter(all_train_labels)\n",
        "\n",
        "# Convert label IDs to names and print the counts\n",
        "print(\"Distribution of Label Types in converted_train.json (using corrected labels):\")\n",
        "for label_id, count in label_id_counts.items():\n",
        "    label_name = id2label.get(label_id, f\"Unknown ID: {label_id}\")\n",
        "    print(f\"{label_name}: {count}\")"
      ],
      "metadata": {
        "id": "f49Re26R1LRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar Dataset Train convertido para Alimentar Input Treinamento do Modelo\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"converted_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    converted_train_data = json.load(f)\n",
        "\n",
        "# Print the first 5 entries\n",
        "for i, entry in enumerate(converted_train_data[:5]):\n",
        "    print(entry)\n",
        "    if i == 4:\n",
        "        break"
      ],
      "metadata": {
        "id": "ZZg9CUnN1qxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar Estrutura Sequência para Input_ID e Label para Treinamento do Modelo\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"converted_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    converted_train_data = json.load(f)\n",
        "\n",
        "print(\"Structure of input_ids and labels:\")\n",
        "for i, entry in enumerate(converted_train_data[:3]): # Displaying first 3 examples\n",
        "    print(f\"--- Example {i+1} ---\")\n",
        "    print(f\"  input_ids: {entry['input_ids']}\")\n",
        "    print(f\"  Length of input_ids: {len(entry['input_ids'])}\")\n",
        "    print(f\"  labels: {entry['labels']}\")\n",
        "    print(f\"  Length of labels: {len(entry['labels'])}\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "UOeT3OAz2MP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Distribuião Comprimento da Sequência dos Dados Convertidos para Treino\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the converted data\n",
        "with open(\"converted_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    converted_train_data = json.load(f)\n",
        "\n",
        "with open(\"converted_dev.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    converted_dev_data = json.load(f)\n",
        "\n",
        "# Get the lengths of the labels sequences\n",
        "train_label_lengths = [len(entry[\"labels\"]) for entry in converted_train_data]\n",
        "dev_label_lengths = [len(entry[\"labels\"]) for entry in converted_dev_data]\n",
        "\n",
        "# Combine lengths for visualization\n",
        "all_label_lengths = train_label_lengths + dev_label_lengths\n",
        "\n",
        "# Create a histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(all_label_lengths, bins=50, edgecolor='black')\n",
        "plt.xlabel(\"Sequence Length (Number of Tokens)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Sequence Lengths in Converted Data\")\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Minimum sequence length: {min(all_label_lengths)}\")\n",
        "print(f\"Maximum sequence length: {max(all_label_lengths)}\")\n",
        "print(f\"Average sequence length: {sum(all_label_lengths) / len(all_label_lengths):.2f}\")"
      ],
      "metadata": {
        "id": "Y7vnxGl-2cDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Distribuição Label Type Dos Dados Convertidos para Treino\n",
        "\n",
        "from collections import Counter\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the converted training data\n",
        "with open(\"converted_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    converted_train_data = json.load(f)\n",
        "\n",
        "# Load id2label mapping from the corrected file\n",
        "def load_label_set(label_file: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
        "    labels = []\n",
        "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            t = line.strip()\n",
        "            if t:\n",
        "                labels.append(t)\n",
        "    if \"O\" not in labels:\n",
        "        labels = [\"O\"] + labels\n",
        "    label2id = {l: i for i, l in enumerate(labels)}\n",
        "    id2label = {i: l for l, i in label2id.items()}\n",
        "    return label2id, id2label\n",
        "\n",
        "label2id, id2label = load_label_set(\"crf_ent2id_corrected.txt\")\n",
        "\n",
        "# Extract all label IDs from the training data\n",
        "all_train_labels = []\n",
        "for entry in converted_train_data:\n",
        "    all_train_labels.extend(entry[\"labels\"])\n",
        "\n",
        "# Count the occurrences of each label ID\n",
        "label_id_counts = Counter(all_train_labels)\n",
        "\n",
        "# Convert label IDs to names and prepare for plotting\n",
        "label_names = [id2label.get(label_id, f\"Unknown ID: {label_id}\") for label_id in label_id_counts.keys()]\n",
        "counts = list(label_id_counts.values())\n",
        "\n",
        "# Sort labels by count for better visualization\n",
        "sorted_labels_and_counts = sorted(zip(label_names, counts), key=lambda item: item[1], reverse=True)\n",
        "sorted_label_names = [item[0] for item in sorted_labels_and_counts]\n",
        "sorted_counts = [item[1] for item in sorted_labels_and_counts]\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(15, 7)) # Increased figure size for better readability\n",
        "plt.bar(sorted_label_names, sorted_counts)\n",
        "plt.xlabel(\"Label Type\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Label Types in Converted Training Data (Corrected Labels)\")\n",
        "plt.xticks(rotation=90) # Rotate labels to prevent overlap\n",
        "plt.tight_layout() # Adjust layout to prevent labels from being cut off\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gs43KU_A2-bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Distribuição Label Type Dos Dados Convertidos para Treino (Exclusão Label Type \"O\" = Others)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the converted training data\n",
        "with open(\"converted_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    converted_train_data = json.load(f)\n",
        "\n",
        "# Load id2label mapping from the corrected file\n",
        "def load_label_set(label_file: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
        "    labels = []\n",
        "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            t = line.strip()\n",
        "            if t:\n",
        "                labels.append(t)\n",
        "    if \"O\" not in labels:\n",
        "        labels = [\"O\"] + labels\n",
        "    label2id = {l: i for i, l in enumerate(labels)}\n",
        "    id2label = {i: l for l, i in label2id.items()}\n",
        "    return label2id, id2label\n",
        "\n",
        "label2id, id2label = load_label_set(\"crf_ent2id_corrected.txt\")\n",
        "\n",
        "# Extract all label IDs from the training data\n",
        "all_train_labels = []\n",
        "for entry in converted_train_data:\n",
        "    all_train_labels.extend(entry[\"labels\"])\n",
        "\n",
        "# Count the occurrences of each label ID\n",
        "label_id_counts = Counter(all_train_labels)\n",
        "\n",
        "# Convert label IDs to names and prepare for plotting, excluding the 'O' label\n",
        "label_names = []\n",
        "counts = []\n",
        "for label_id, count in label_id_counts.items():\n",
        "    label_name = id2label.get(label_id, f\"Unknown ID: {label_id}\")\n",
        "    if label_name != 'O': # Exclude the 'O' label\n",
        "        label_names.append(label_name)\n",
        "        counts.append(count)\n",
        "\n",
        "# Sort labels by count for better visualization\n",
        "sorted_labels_and_counts = sorted(zip(label_names, counts), key=lambda item: item[1], reverse=True)\n",
        "sorted_label_names = [item[0] for item in sorted_labels_and_counts]\n",
        "sorted_counts = [item[1] for item in sorted_labels_and_counts]\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(15, 7)) # Increased figure size for better readability\n",
        "plt.bar(sorted_label_names, sorted_counts)\n",
        "plt.xlabel(\"Label Type (Excluding 'O')\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Label Types in Converted Training Data (Excluding 'O')\")\n",
        "plt.xticks(rotation=90) # Rotate labels to prevent overlap\n",
        "plt.tight_layout() # Adjust layout to prevent labels from being cut off\n",
        "plt.show()\n",
        "\n",
        "print(\"Exact frequency of label types (excluding 'O'):\")\n",
        "for name, count in sorted_labels_and_counts:\n",
        "    print(f\"{name}: {count}\")"
      ],
      "metadata": {
        "id": "Ssg0Gxq13PYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparativo Exemplo Amostra Texto Original e Texto Convertido\n",
        "\n",
        "import json\n",
        "\n",
        "# Load original training data\n",
        "with open(\"train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    original_train_data = json.load(f)\n",
        "\n",
        "# Load converted training data\n",
        "with open(\"converted_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    converted_train_data = json.load(f)\n",
        "\n",
        "# Load id2label mapping from the corrected file\n",
        "def load_label_set(label_file: str) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
        "    labels = []\n",
        "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            t = line.strip()\n",
        "            if t:\n",
        "                labels.append(t)\n",
        "    if \"O\" not in labels:\n",
        "        labels = [\"O\"] + labels\n",
        "    label2id = {l: i for i, l in enumerate(labels)}\n",
        "    id2label = {i: l for l, i in label2id.items()}\n",
        "    return label2id, id2label\n",
        "\n",
        "label2id, id2label = load_label_set(\"crf_ent2id_corrected.txt\")\n",
        "\n",
        "\n",
        "# Display the first few examples\n",
        "for i in range(3): # Displaying first 3 examples\n",
        "    original_entry = original_train_data[i]\n",
        "    converted_entry = converted_train_data[i]\n",
        "\n",
        "    print(f\"--- Example {i+1} ---\")\n",
        "    print(\"Original Text:\")\n",
        "    print(original_entry['text'])\n",
        "    print(\"\\nConverted Data:\")\n",
        "    print(f\"  ID: {converted_entry['id']}\")\n",
        "    print(f\"  Input IDs: {converted_entry['input_ids']}\")\n",
        "    print(f\"  Attention Mask: {converted_entry['attention_mask']}\")\n",
        "    print(f\"  Labels (IDs): {converted_entry['labels']}\")\n",
        "\n",
        "    # Convert label IDs to names for better readability\n",
        "    label_names = [id2label[label_id] for label_id in converted_entry['labels']]\n",
        "    print(f\"  Labels (Names): {label_names}\")\n",
        "\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "BOLH8GgF3nIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar Alinhamento do Texto Após da Limpeza\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "import json\n",
        "import re\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Limpeza HTML espaçõ\"\"\"\n",
        "    text = re.sub(r\"<br\\s*/?>\", \"\", text)\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    text = text.replace(\"\\u3000\", \" \")\n",
        "    return text\n",
        "\n",
        "def load_sample(path, sample_id=None):\n",
        "    data = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
        "\n",
        "    # Listar primeiros 50 id\n",
        "    ids = [d[\"id\"] for d in data]\n",
        "    print(\"所有可用的 id:\", ids[:50])\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    if sample_id is None:\n",
        "        return data[0]\n",
        "    for d in data:\n",
        "        if str(d[\"id\"]) == str(sample_id):\n",
        "            return d\n",
        "    raise ValueError(f\"找不到 id={sample_id} 的樣本\")\n",
        "\n",
        "def spans_to_bioes(text, spans):\n",
        "    labels = [\"O\"] * len(text)\n",
        "    for s in spans:\n",
        "        if len(s) < 4: continue\n",
        "        typ = s[1]\n",
        "        st, ed = int(s[2]), int(s[3])\n",
        "        if ed <= st or st < 0 or ed > len(text): continue\n",
        "        if ed - st == 1:\n",
        "            labels[st] = f\"S-{typ}\"\n",
        "        else:\n",
        "            labels[st] = f\"B-{typ}\"\n",
        "            for i in range(st+1, ed-1):\n",
        "                labels[i] = f\"I-{typ}\"\n",
        "            labels[ed-1] = f\"E-{typ}\"\n",
        "    return labels\n",
        "\n",
        "def debug_one(sample, tokenizer):\n",
        "    # Before tokenizer fazer limpeza\n",
        "    raw_text = sample[\"text\"]\n",
        "    text = clean_text(raw_text)\n",
        "\n",
        "    spans = sample.get(\"labels\", [])\n",
        "    print(\"=== 原文（清洗後）===\")\n",
        "    print(text)\n",
        "    print(\"\\n=== Gold spans ===\")\n",
        "    for s in spans:\n",
        "        print(s)\n",
        "\n",
        "    gold_bioes = spans_to_bioes(text, spans)\n",
        "\n",
        "    # Correct tokenizer mapping\n",
        "    enc = tokenizer(text, return_offsets_mapping=True,\n",
        "                    truncation=True, max_length=512)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(enc[\"input_ids\"])\n",
        "    offsets = enc[\"offset_mapping\"]\n",
        "\n",
        "    print(\"\\n=== Token Check Alinhamento ===\")\n",
        "    for i, (tok, (st, ed)) in enumerate(zip(tokens, offsets)):\n",
        "        if st == ed == 0:\n",
        "            label = \"O\"\n",
        "        elif st < len(gold_bioes):\n",
        "            label = gold_bioes[st]\n",
        "        else:\n",
        "            label = \"O\"\n",
        "        frag = text[st:ed] if st < ed else \"\"\n",
        "        print(f\"{i:3d} | token={tok:8s} | offset=({st:3d},{ed:3d}) | text='{frag}' | label={label}\")\n",
        "\n",
        "# Notebook main\n",
        "def main(data_json=\"Train_data.json\", sample_id=None, model_name=\"hfl/chinese-bert-wwm-ext\"):\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "    sample = load_sample(data_json, sample_id)\n",
        "    debug_one(sample, tokenizer)\n",
        "\n",
        "# Parâmetro\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data_json\", type=str, default=\"train.json\")\n",
        "    parser.add_argument(\"--sample_id\", type=str, default=923)\n",
        "    parser.add_argument(\"--model_name\", type=str, default=\"hfl/chinese-bert-wwm-ext\")\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    main(data_json=args.data_json, sample_id=args.sample_id, model_name=args.model_name)"
      ],
      "metadata": {
        "id": "8WLsKr0t4bQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento do Modelo Alibaba QWEN3-0.6B LLM"
      ],
      "metadata": {
        "id": "aJqoTlC7-zBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test:7 Batch Size:2 Grad Accum Steps:4 Warmup Ratio:0.1 Dropout:0.1 Epochs:20"
      ],
      "metadata": {
        "id": "7SZS_pVq_TsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "train_ner_final.py\n",
        "Read convert_bioes_final.py Output JSON（input_ids/attention_mask/labels），\n",
        "Qwen(+CRF True/False) Training NER，：\n",
        "- Gradient Accumlative Steps (grad_accum_steps)\n",
        "- AMP Automatic Mixed Precision (torch.cuda.amp.autocast + GradScaler)\n",
        "- Scheduler Based on parameter update steps\n",
        "- Training Monitoring: Loss/F1 curves\n",
        "- Best Model / Training Log CSV / Training Curves PNG\n",
        "\n",
        "- Train F1 + Validation F1\n",
        "- Plot Curves (Loss / Train F1 / Val F1)\n",
        "- Download outputs_qwen_ner/\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "from torchcrf import CRF\n",
        "from torch.optim import AdamW\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# OOM\n",
        "#import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# ========== DATA ==========\n",
        "class NERJsonDataset(Dataset):\n",
        "    def __init__(self, path: str):\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            self.items = json.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.items[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(ex[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(ex[\"attention_mask\"], dtype=torch.long),\n",
        "            \"labels\": torch.tensor(ex[\"labels\"], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "def pad_collate(batch, pad_token_id=0, pad_label_id=0):\n",
        "    max_len = max(len(x[\"input_ids\"]) for x in batch)\n",
        "    out = {}\n",
        "    for k in [\"input_ids\", \"attention_mask\", \"labels\"]:\n",
        "        seqs = []\n",
        "        for x in batch:\n",
        "            t = x[k]\n",
        "            pad_id = pad_token_id if k != \"labels\" else pad_label_id\n",
        "            if len(t) < max_len:\n",
        "                t = torch.cat([t, torch.full((max_len - len(t),), pad_id, dtype=t.dtype)])\n",
        "            seqs.append(t)\n",
        "        out[k] = torch.stack(seqs)\n",
        "    return out\n",
        "\n",
        "# ========== MODEL ==========\n",
        "class QwenForTokenClassification(nn.Module):\n",
        "    def __init__(self, model_name: str, num_labels: int, use_crf: bool = False, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.backbone = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n",
        "        self.use_crf = use_crf\n",
        "        if use_crf:\n",
        "            self.crf = CRF(num_labels, batch_first=True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        seq = self.dropout(out.last_hidden_state)\n",
        "        logits = self.classifier(seq)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.use_crf:\n",
        "                loss = -self.crf(logits, labels, mask=attention_mask.bool(), reduction='mean')\n",
        "            else:\n",
        "                active = attention_mask.view(-1) == 1\n",
        "                loss_fct = nn.CrossEntropyLoss()\n",
        "                loss = loss_fct(\n",
        "                    logits.view(-1, logits.size(-1))[active],\n",
        "                    labels.view(-1)[active]\n",
        "                )\n",
        "\n",
        "        if self.use_crf:\n",
        "            pred = self.crf.decode(logits, mask=attention_mask.bool())\n",
        "            max_len = logits.size(1)\n",
        "            pred = torch.tensor([p + [0] * (max_len - len(p)) for p in pred], dtype=torch.long, device=logits.device)\n",
        "        else:\n",
        "            pred = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        return {\"loss\": loss, \"pred_ids\": pred, \"logits\": logits}\n",
        "\n",
        "# ========== ALIGN EVALUATE ==========\n",
        "def align_eval(pred_ids, labels, attention_mask, id2label):\n",
        "    preds, trues = [], []\n",
        "    bs, L = pred_ids.size()\n",
        "    for i in range(bs):\n",
        "        p_seq, t_seq = [], []\n",
        "        for j in range(L):\n",
        "            if attention_mask[i, j].item() == 1:\n",
        "                p_seq.append(id2label[pred_ids[i, j].item()])\n",
        "                t_seq.append(id2label[labels[i, j].item()])\n",
        "        preds.append(p_seq)\n",
        "        trues.append(t_seq)\n",
        "    return preds, trues\n",
        "\n",
        "# ========== MAIN ==========\n",
        "def main(argv=None):\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--converted_train\", type=str, default=\"converted_train.json\")\n",
        "    parser.add_argument(\"--converted_dev\", type=str, default=\"converted_dev.json\")\n",
        "    parser.add_argument(\"--labels_file\", type=str, default=\"crf_ent2id_corrected.txt\")\n",
        "    parser.add_argument(\"--model_name\", type=str, default=\"Qwen/Qwen3-0.6B\")\n",
        "\n",
        "    parser.add_argument(\"--output_dir\", type=str, default=\"outputs_qwen_ner\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=2)\n",
        "    parser.add_argument(\"--epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--lr\", type=float, default=3e-5)\n",
        "    parser.add_argument(\"--warmup_ratio\", type=float, default=0.1)\n",
        "    parser.add_argument(\"--dropout\", type=float, default=0.1)\n",
        "\n",
        "    parser.add_argument(\"--use_crf\", action=\"store_true\", default=True)\n",
        "    parser.add_argument(\"--grad_accum_steps\", type=int, default=4, help=\"Gradient Accumulative Steps（Ex: 4）\")\n",
        "    parser.add_argument(\"--use_amp\", action=\"store_true\", default=True, help=\"Active AMP Automatic Mixed Precision（CUDA）\")\n",
        "    if argv is None:\n",
        "        args, _ = parser.parse_known_args()\n",
        "    else:\n",
        "        args = parser.parse_args(argv)\n",
        "\n",
        "    print(f\"Model: {args.model_name} | Batch size: {args.batch_size} | \"\n",
        "          f\"CRF enabled: {args.use_crf} | GradAccum: {args.grad_accum_steps} | \"\n",
        "          f\"Epochs: {args.epochs} | LR: {args.lr} | Warmup ratio: {args.warmup_ratio} | \"\n",
        "          f\"AMP: {args.use_amp} | Dropout: {args.dropout}\")\n",
        "\n",
        "    # LABEL\n",
        "    with open(args.labels_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        labels = [l.strip() for l in f if l.strip()]\n",
        "    if \"O\" not in labels:\n",
        "        labels = [\"O\"] + labels\n",
        "    label2id = {l: i for i, l in enumerate(labels)}\n",
        "    id2label = {i: l for l, i in label2id.items()}\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
        "\n",
        "    # DATA and DataLoader\n",
        "    train_ds = NERJsonDataset(args.converted_train)\n",
        "    dev_ds = NERJsonDataset(args.converted_dev)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=lambda b: pad_collate(\n",
        "            b,\n",
        "            pad_token_id=tokenizer.pad_token_id or 0,\n",
        "            pad_label_id=label2id[\"O\"]\n",
        "        )\n",
        "    )\n",
        "    dev_loader = DataLoader(\n",
        "        dev_ds,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=lambda b: pad_collate(\n",
        "            b,\n",
        "            pad_token_id=tokenizer.pad_token_id or 0,\n",
        "            pad_label_id=label2id[\"O\"]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = QwenForTokenClassification(\n",
        "        args.model_name,\n",
        "        num_labels=len(label2id),\n",
        "        use_crf=args.use_crf,\n",
        "        dropout=args.dropout\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=args.lr)\n",
        "\n",
        "    # UPDATE BASED PARAMETERS scheduler\n",
        "    total_update_steps = (len(train_loader) * args.epochs) // max(args.grad_accum_steps, 1)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=int(total_update_steps * args.warmup_ratio),\n",
        "        num_training_steps=total_update_steps\n",
        "    )\n",
        "\n",
        "    # AMP\n",
        "    use_amp = args.use_amp and torch.cuda.is_available()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "    autocast = torch.cuda.amp.autocast\n",
        "\n",
        "    # ====== MONITORING / RECORD ======\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "    train_losses, train_f1s, val_f1s = [], [], []\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        # ===== TRAINING =====\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for step, batch in enumerate(train_loader, 1):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            with autocast(enabled=use_amp):\n",
        "                out = model(input_ids, attention_mask, labels)\n",
        "                loss = out[\"loss\"]\n",
        "\n",
        "            # GRADIENT ACCUMULATIVE STEPS\n",
        "            loss = loss / max(args.grad_accum_steps, 1)\n",
        "            scaler.scale(loss).backward()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if step % max(args.grad_accum_steps, 1) == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        # ===== EVALUATE =====\n",
        "        model.eval()\n",
        "        all_preds_val, all_trues_val = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in dev_loader:\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "                out = model(input_ids, attention_mask, labels=None)\n",
        "                preds, trues = align_eval(out[\"pred_ids\"], labels, attention_mask, id2label)\n",
        "                all_preds_val.extend(preds)\n",
        "                all_trues_val.extend(trues)\n",
        "\n",
        "        f1_val = f1_score(all_trues_val, all_preds_val)\n",
        "        p_val = precision_score(all_trues_val, all_preds_val)\n",
        "        r_val = recall_score(all_trues_val, all_preds_val)\n",
        "        val_f1s.append(f1_val)\n",
        "\n",
        "        # ===== TRAIN F1 =====\n",
        "        all_preds_train, all_trues_train = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in train_loader:\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "                out = model(input_ids, attention_mask, labels=None)\n",
        "                preds, trues = align_eval(out[\"pred_ids\"], labels, attention_mask, id2label)\n",
        "                all_preds_train.extend(preds)\n",
        "                all_trues_train.extend(trues)\n",
        "        f1_train = f1_score(all_trues_train, all_preds_train)\n",
        "        train_f1s.append(f1_train)\n",
        "\n",
        "        print(f\"Epoch {epoch} | Loss={avg_loss:.4f} | \"\n",
        "              f\"TrainF1={f1_train:.4f} | ValF1={f1_val:.4f} | P={p_val:.4f} | R={r_val:.4f}\")\n",
        "        print(classification_report(all_trues_val, all_preds_val, digits=4))\n",
        "\n",
        "\n",
        "\n",
        "        # BEST MODEL RECORD（VALIDATION F1）\n",
        "        if f1_val > best_f1:\n",
        "            best_f1 = f1_val\n",
        "            torch.save(model.state_dict(), os.path.join(args.output_dir, \"pytorch_model.bin\"))\n",
        "            tokenizer.save_pretrained(args.output_dir)\n",
        "            with open(os.path.join(args.output_dir, \"label2id.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(label2id, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Saved best model to {args.output_dir} (F1={best_f1:.4f})\")\n",
        "\n",
        "    print(f\"Training finished. Best F1: {best_f1:.4f}\")\n",
        "\n",
        "    # ===== PLOT Loss/F1 CURVES =====\n",
        "    epochs_axis = range(1, len(train_losses)+1)\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax1.plot(epochs_axis, train_losses, 'r-o', label='Train Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss', color='r')\n",
        "    ax1.tick_params(axis='y', labelcolor='r')\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(epochs_axis, val_f1s, 'b-s', label='Validation F1')\n",
        "    ax2.set_ylabel('F1 Score', color='b')\n",
        "    ax2.tick_params(axis='y', labelcolor='b')\n",
        "    fig.suptitle('Training Progress: Loss vs F1')\n",
        "    ax1.grid(True)\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(args.output_dir, \"training_curves.png\"))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "    # ===== PLOT 3 LINE CURVES =====\n",
        "    epochs_axis = range(1, len(train_losses)+1)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(epochs_axis, train_losses, 'r-o', label='Train Loss')\n",
        "    plt.plot(epochs_axis, train_f1s, 'g-^', label='Train F1')\n",
        "    plt.plot(epochs_axis, val_f1s, 'b-s', label='Validation F1')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Value')\n",
        "    plt.title('Training Progress: Loss vs Train F1 vs Validation F1')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    curve_path = os.path.join(args.output_dir, \"training_curves_three.png\")\n",
        "    plt.savefig(curve_path)\n",
        "    plt.show()\n",
        "    print(f\"Curves image saved to {curve_path}\")\n",
        "\n",
        "    # ===== RECORD LOG CSV =====\n",
        "    log_df = pd.DataFrame({\n",
        "        \"epoch\": list(range(1, len(train_losses)+1)),\n",
        "        \"train_loss\": train_losses,\n",
        "        \"val_f1\": val_f1s\n",
        "    })\n",
        "    log_path = os.path.join(args.output_dir, \"training_log.csv\")\n",
        "    log_df.to_csv(log_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"Training log saved to {log_path}\")\n",
        "    print(f\"Curves image saved to {os.path.join(args.output_dir, 'training_curves.png')}\")\n",
        "\n",
        "\n",
        "    # ===== DOWNLOAD =====\n",
        "    import shutil\n",
        "    zip_path = f\"{args.output_dir}.zip\"\n",
        "    shutil.make_archive(args.output_dir, 'zip', args.output_dir)\n",
        "    print(f\"📦 Finish：{zip_path}\")\n",
        "\n",
        "    # Colab Download Automatic（Not Colab，Fail，Manual）\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(zip_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Automatic download skipped（Not Colab or Download Failed）：{e}\")\n",
        "        print(f\"Please download manually：{zip_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Eb15XhaQ_fPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predição Teste"
      ],
      "metadata": {
        "id": "v37EUUPDFh7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict Avaliação com Test_Gold ou Test"
      ],
      "metadata": {
        "id": "riePo16xGNYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict_eval_final.py\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torchcrf import CRF\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "\n",
        "# ===== MODEL TYPE =====\n",
        "class QwenForTokenClassification(nn.Module):\n",
        "    def __init__(self, model_name: str, num_labels: int, use_crf: bool = True, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.backbone = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n",
        "        self.crf = CRF(num_labels, batch_first=True) if use_crf else None\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # input_ids: [B, L], attention_mask: [B, L]\n",
        "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        seq = self.dropout(out.last_hidden_state)           # [B, L, H]\n",
        "        emissions = self.classifier(seq)                    # [B, L, num_labels]\n",
        "        if self.crf is None:\n",
        "            return emissions.argmax(dim=-1)                 # [B, L]\n",
        "        # CRF decode RETURN list[list[int]]（DIFF SEQUENCE LENGTH）\n",
        "        pred_paths = self.crf.decode(emissions, mask=attention_mask.bool())\n",
        "        max_len = emissions.size(1)\n",
        "        # PADDED WITH O TYPE（id=0）FIX LENGTH\n",
        "        padded = torch.tensor(\n",
        "            [p + [0] * (max_len - len(p)) for p in pred_paths],\n",
        "            dtype=torch.long,\n",
        "            device=emissions.device\n",
        "        )                                                   # [B, L]\n",
        "        return padded\n",
        "\n",
        "\n",
        "# ===== BIOES → spans DECODE（end WITHOUT） =====\n",
        "def bioes_to_spans(labels, offsets):\n",
        "    ents = []\n",
        "    cur_lab, cur_s, cur_e = None, None, None\n",
        "    for lab, (s, e) in zip(labels, offsets):\n",
        "        if lab.startswith(\"B-\"):\n",
        "            cur_lab = lab[2:]; cur_s = s; cur_e = e\n",
        "        elif lab.startswith(\"I-\") and cur_lab == lab[2:]:\n",
        "            cur_e = e\n",
        "        elif lab.startswith(\"E-\") and cur_lab == lab[2:]:\n",
        "            cur_e = e\n",
        "            ents.append((cur_s, cur_e, cur_lab))\n",
        "            cur_lab, cur_s, cur_e = None, None, None\n",
        "        elif lab.startswith(\"S-\"):\n",
        "            ents.append((s, e, lab[2:]))\n",
        "            cur_lab, cur_s, cur_e = None, None, None\n",
        "        else:\n",
        "            # O OR DISCONTINUOUS\n",
        "            cur_lab, cur_s, cur_e = None, None, None\n",
        "    return ents\n",
        "\n",
        "\n",
        "# ===== SINGLE SAMPLE TEXT → spans PREDICT =====\n",
        "def predict_spans(text, tokenizer, model, id2label, device):\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        return_offsets_mapping=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True\n",
        "    )\n",
        "    offsets = enc[\"offset_mapping\"][0].tolist()\n",
        "    input_ids = enc[\"input_ids\"].to(device)\n",
        "    attention_mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_ids = model(input_ids=input_ids, attention_mask=attention_mask)[0].tolist()\n",
        "\n",
        "    pred_labels = [id2label[i] for i in pred_ids]\n",
        "    valid_offsets, valid_labels = [], []\n",
        "    for lab, off in zip(pred_labels, offsets):\n",
        "        # FILTER SPECIAL token（WHEN offset = (0,0)）\n",
        "        if off != [0, 0] and off != (0, 0):\n",
        "            valid_offsets.append(tuple(off))\n",
        "            valid_labels.append(lab)\n",
        "    return bioes_to_spans(valid_labels, valid_offsets)\n",
        "\n",
        "\n",
        "def span_key(s, e, l):\n",
        "    return f\"{s}-{e}-{l}\"\n",
        "\n",
        "\n",
        "# ===== ENTITY EVALUATE =====\n",
        "def evaluate_entity_level(gold_items, tokenizer, model, id2label, device):\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "    per_type = defaultdict(lambda: Counter({\"tp\": 0, \"fp\": 0, \"fn\": 0}))\n",
        "\n",
        "    for item in gold_items:\n",
        "        text = item[\"text\"]\n",
        "        pred_spans = predict_spans(text, tokenizer, model, id2label, device)\n",
        "        gold_spans = [(ent[\"start\"], ent[\"end\"], ent[\"label\"]) for ent in item[\"entities\"]]\n",
        "\n",
        "        pred_set = {span_key(*sp) for sp in pred_spans}\n",
        "        gold_set = {span_key(*sp) for sp in gold_spans}\n",
        "\n",
        "        tp_set = pred_set & gold_set\n",
        "        fp_set = pred_set - gold_set\n",
        "        fn_set = gold_set - pred_set\n",
        "\n",
        "        tp += len(tp_set)\n",
        "        fp += len(fp_set)\n",
        "        fn += len(fn_set)\n",
        "\n",
        "        for s, e, l in pred_spans:\n",
        "            if span_key(s, e, l) in tp_set:\n",
        "                per_type[l][\"tp\"] += 1\n",
        "            else:\n",
        "                per_type[l][\"fp\"] += 1\n",
        "        for s, e, l in gold_spans:\n",
        "            if span_key(s, e, l) in fn_set:\n",
        "                per_type[l][\"fn\"] += 1\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    per_type_report = {}\n",
        "    for t, c in per_type.items():\n",
        "        p = c[\"tp\"] / (c[\"tp\"] + c[\"fp\"]) if (c[\"tp\"] + c[\"fp\"]) > 0 else 0.0\n",
        "        r = c[\"tp\"] / (c[\"tp\"] + c[\"fn\"]) if (c[\"tp\"] + c[\"fn\"]) > 0 else 0.0\n",
        "        f = 2 * p * r / (p + r) if (p + r) > 0 else 0.0\n",
        "        support = c[\"tp\"] + c[\"fn\"]\n",
        "        per_type_report[t] = {\n",
        "            \"precision\": round(p, 4),\n",
        "            \"recall\": round(r, 4),\n",
        "            \"f1\": round(f, 4),\n",
        "            \"support\": int(support),\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"micro\": {\n",
        "            \"precision\": round(precision, 4),\n",
        "            \"recall\": round(recall, 4),\n",
        "            \"f1\": round(f1, 4),\n",
        "            \"tp\": int(tp),\n",
        "            \"fp\": int(fp),\n",
        "            \"fn\": int(fn),\n",
        "        },\n",
        "        \"per_type\": per_type_report,\n",
        "    }\n",
        "\n",
        "\n",
        "# ===== NO GOLD STANDARD STATISTICS =====\n",
        "def predict_and_count(test_items, tokenizer, model, id2label, device):\n",
        "    counts = Counter()\n",
        "    all_preds = []\n",
        "    for item in test_items:\n",
        "        text = item[\"text\"]\n",
        "        pred_spans = predict_spans(text, tokenizer, model, id2label, device)\n",
        "        all_preds.append({\n",
        "            \"id\": item.get(\"id\"),\n",
        "            \"text\": text,\n",
        "            \"pred_entities\": [{\"start\": s, \"end\": e, \"label\": l} for s, e, l in pred_spans],\n",
        "        })\n",
        "        for _, _, l in pred_spans:\n",
        "            counts[l] += 1\n",
        "    return all_preds, counts\n",
        "\n",
        "\n",
        "# ===== CSV OUTPUT =====\n",
        "def save_eval_csv(report, output_dir, timestamp):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    micro_df = pd.DataFrame([report[\"micro\"]])\n",
        "    micro_path = os.path.join(output_dir, f\"micro_eval_{timestamp}.csv\")\n",
        "    micro_df.to_csv(micro_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    per_df = pd.DataFrame([{\"label\": lbl, **metrics} for lbl, metrics in report[\"per_type\"].items()])\n",
        "    per_path = os.path.join(output_dir, f\"per_type_eval_{timestamp}.csv\")\n",
        "    per_df.to_csv(per_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    print(f\"✅ OUTPUT CSV：{micro_path}\")\n",
        "    print(f\"✅ OUTPUT CSV：{per_path}\")\n",
        "\n",
        "\n",
        "def save_stats_csv(counts, output_dir, timestamp):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    df = pd.DataFrame([{\"label\": l, \"count\": c} for l, c in counts.items()])\n",
        "    path = os.path.join(output_dir, f\"prediction_stats_{timestamp}.csv\")\n",
        "    df.to_csv(path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"✅ OUTPUT CSV：{path}\")\n",
        "\n",
        "\n",
        "# ===== MAIN =====\n",
        "def main():\n",
        "    # DIRECTORY PATH\n",
        "    output_dir = \"outputs_qwen_ner\"\n",
        "    gold_path = \"test_gold.json\"\n",
        "    test_path = \"test.json\"\n",
        "\n",
        "    # TIMSTAMP\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # DEVICE\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"🖥️ USE DEVICE: {device}\")\n",
        "\n",
        "    # LOAD tokenizer MAP TAG\n",
        "    tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "    with open(os.path.join(output_dir, \"label2id.json\"), \"r\", encoding=\"utf-8\") as f:\n",
        "        label2id = json.load(f)\n",
        "    id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "    # LOAD MODEL\n",
        "    # model_name training backbone name\n",
        "    model = QwenForTokenClassification(model_name=\"Qwen/Qwen3-0.6B\", num_labels=len(label2id))\n",
        "    state = torch.load(os.path.join(output_dir, \"pytorch_model.bin\"), map_location=\"cpu\")\n",
        "    model.load_state_dict(state)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"✅ Best model loaded.\")\n",
        "\n",
        "    if os.path.exists(gold_path):\n",
        "        print(\"🔎 Detected Test_Gold.json → ENTITY EVALUATE\")\n",
        "        gold_items = json.load(open(gold_path, \"r\", encoding=\"utf-8\"))\n",
        "        report = evaluate_entity_level(gold_items, tokenizer, model, id2label, device)\n",
        "\n",
        "        # PRINT micro RESULT\n",
        "        micro = report[\"micro\"]\n",
        "        print(\"=== Entity-level Micro Scores ===\")\n",
        "        print(f\"Precision: {micro['precision']}\")\n",
        "        print(f\"Recall   : {micro['recall']}\")\n",
        "        print(f\"F1       : {micro['f1']}\")\n",
        "        print(f\"TP={micro['tp']}  FP={micro['fp']}  FN={micro['fn']}\")\n",
        "\n",
        "        # PRINT per-type REPORT\n",
        "        print(\"\\n=== Per-type Classification Report ===\")\n",
        "        for t, m in sorted(report[\"per_type\"].items()):\n",
        "            print(f\"{t:25s}  P={m['precision']:.4f}  R={m['recall']:.4f}  F1={m['f1']:.4f}  Support={m['support']}\")\n",
        "\n",
        "        # SAVE CSV\n",
        "        save_eval_csv(report, output_dir=output_dir, timestamp=timestamp)\n",
        "\n",
        "    else:\n",
        "        print(\"🔎 NOT FOUND Test_Gold.json → USE Test.json DO PREDICTIVE STATISTICS\")\n",
        "        test_items = json.load(open(test_path, \"r\", encoding=\"utf-8\"))\n",
        "        preds, counts = predict_and_count(test_items, tokenizer, model, id2label, device)\n",
        "\n",
        "        # PRINT STATISTICS\n",
        "        print(\"=== Prediction Statistics (Counts by label) ===\")\n",
        "        for l, c in sorted(counts.items()):\n",
        "            print(f\"{l:25s}: {c}\")\n",
        "\n",
        "        # SAVE PREDICT JSON\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        pred_path = os.path.join(output_dir, f\"Test_Pred_{timestamp}.json\")\n",
        "        with open(pred_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(preds, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"✅ PREDICTION RESULTS HAVE BEEN OUTPU TO  {pred_path}\")\n",
        "\n",
        "        # SAVE CSV STATISTICS\n",
        "        save_stats_csv(counts, output_dir=output_dir, timestamp=timestamp)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "RANwmZeMGqBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregar Modelo Treinado pelo GitHub Repositório"
      ],
      "metadata": {
        "id": "27hGnDGLJ96v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "output_dir = \"/content/outputs_qwen_ner\"\n",
        "\n",
        "# LOAD tokenizer AND label2id\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "with open(f\"{output_dir}/label2id.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    label2id = json.load(f)\n",
        "id2label = {v:k for k,v in label2id.items()}\n",
        "\n",
        "# DEFINE CUSTOM MODEL\n",
        "class QwenForTokenClassification(nn.Module):\n",
        "    def __init__(self, model_name: str, num_labels: int, use_crf: bool = True, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.backbone = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n",
        "        self.crf = CRF(num_labels, batch_first=True) if use_crf else None\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        seq = self.dropout(out.last_hidden_state)\n",
        "        emissions = self.classifier(seq)\n",
        "        if self.crf:\n",
        "            paths = self.crf.decode(emissions, mask=attention_mask.bool())\n",
        "            max_len = emissions.size(1)\n",
        "            padded = torch.tensor([p + [0]*(max_len - len(p)) for p in paths], dtype=torch.long)\n",
        "            return padded\n",
        "        else:\n",
        "            return emissions.argmax(dim=-1)\n",
        "\n",
        "# LOAD THE OPTIMAL MODEL WEIGHTS\n",
        "model = QwenForTokenClassification(model_name=\"Qwen/Qwen3-0.6B\", num_labels=len(label2id))\n",
        "model.load_state_dict(torch.load(f\"{output_dir}/pytorch_model.bin\", map_location=\"cpu\"))\n",
        "model.eval()\n",
        "print(\"✅ Best model loaded from GitHub repo\")"
      ],
      "metadata": {
        "id": "QTG2PKgKKGjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUICK PREDICT TEST (SINGLE SENTENCE / OUTPUT SPAN)\n",
        "\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def bioes_to_spans(labels, offsets):\n",
        "    ents, cur_lab, cur_s, cur_e = [], None, None, None\n",
        "    for lab, (s, e) in zip(labels, offsets):\n",
        "        if lab.startswith(\"B-\"):\n",
        "            cur_lab, cur_s, cur_e = lab[2:], s, e\n",
        "        elif lab.startswith(\"I-\") and cur_lab == lab[2:]:\n",
        "            cur_e = e\n",
        "        elif lab.startswith(\"E-\") and cur_lab == lab[2:]:\n",
        "            cur_e = e\n",
        "            ents.append((cur_s, cur_e, cur_lab))\n",
        "            cur_lab, cur_s, cur_e = None, None, None\n",
        "        elif lab.startswith(\"S-\"):\n",
        "            ents.append((s, e, lab[2:]))\n",
        "            cur_lab, cur_s, cur_e = None, None, None\n",
        "        else:\n",
        "            cur_lab, cur_s, cur_e = None, None, None\n",
        "    return ents\n",
        "\n",
        "\n",
        "def predict_spans(text):\n",
        "    enc = tokenizer(text, return_offsets_mapping=True, return_tensors=\"pt\", truncation=True)\n",
        "    offsets = enc[\"offset_mapping\"][0].tolist()\n",
        "    input_ids = enc[\"input_ids\"].to(device)\n",
        "    attention_mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_ids = model(input_ids=input_ids, attention_mask=attention_mask)[0].tolist()\n",
        "\n",
        "    pred_labels = [id2label[i] for i in pred_ids]\n",
        "    valid_offsets, valid_labels = [], []\n",
        "    for lab, off in zip(pred_labels, offsets):\n",
        "        if off != [0, 0] and off != (0, 0):\n",
        "            valid_offsets.append(tuple(off))\n",
        "            valid_labels.append(lab)\n",
        "    return bioes_to_spans(valid_labels, valid_offsets)\n",
        "\n",
        "#sample_text = \"患者服用某藥物後出現頭痛與噁心，建議與食物同服。\"\n",
        "sample_text = \"本品为黑褐色颗粒；气香，味甜。  株洲千金药业股份有限公司  忌生冷辛辣，孕妇禁服。  开水冲服，一次12g，一日2次。  12g*10袋 补益气血，祛瘀生新。用于气血两虚兼血瘀证产后腹痛 动物试验表明，补血益母颗粒能使失血性贫血小鼠RBC、Hb恢复至正常水平;能对抗环磷酰胺损伤骨髓造血系统所致的血细胞减少，能使WBC、HB、RBC明显升高;且对环磷酰胺所致小鼠脾脏萎缩有明显的对抗作用;它对小鼠既具有活血作用又能缩短小鼠的凝血时间;提高小鼠巨噬细胞的吞噬功能和促进小鼠溶血素抗体的形成;促进小鼠腹腔绵羊红细胞的吸收;但对正常大鼠离体子宫平滑肌未显示出作用。  12g*10袋/盒。  1.忌食寒凉、生冷食物。2.感冒时不宜服用。3.平素月经正常，突然出现月经量少，或月经错后，或阴道不规则出血应去医院就诊。4.按照用法用量服用，长期服用应向医师咨询。5.服药二周症状无改善，应去医院就诊。6.对本品过敏者禁用，过敏体质者慎用。7.本品性状发生改变时禁止使用。8.请将本品放在儿童过敏体质者慎用。7.本品性状发生改变时禁止使用。8.请将本品放在儿童不能接触的地方。9.如正在使用其他药品，使用本品前请咨询医师或药师。  尚不明确。\"\n",
        "\n",
        "spans = predict_spans(sample_text)\n",
        "print(\"Pred spans:\", spans)\n",
        "for s, e, l in spans:\n",
        "    print(f\"[{l}] {sample_text[s:e]}\")"
      ],
      "metadata": {
        "id": "iV-1BetNKs7o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}